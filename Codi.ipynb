{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TThJUYZ9S5fH"
   },
   "source": [
    "### REPTE 3: Histologia digital - Mar Blazquez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AKMBU4RikXGk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import math\n",
    "import itertools\n",
    "from torch import nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from numpy.matlib import repmat\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "import cv2\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "# save dicts to csv\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "hUmBINgIigOR"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def get_fred(model, dataloader,device):\n",
    "    model.eval()  # Cambiar el modelo a modo evaluación\n",
    "    fred_values = []  # Almacenar los valores de F_red\n",
    "\n",
    "    if device == 'cuda' and torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    j=0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i,images in enumerate(dataloader):\n",
    "            if type(images) == list:\n",
    "                # images to tensor\n",
    "                image = images[0]\n",
    "                image = image.to(device)\n",
    "                image = image/255.0\n",
    "            else:\n",
    "                # Enviar imágenes al dispositivo\n",
    "                images = images.to(device)\n",
    "                image = images/255.0\n",
    "\n",
    "            # Obtener las reconstrucciones del modelo\n",
    "            reconstructed = model(image)\n",
    "\n",
    "            # permute HWC\n",
    "            image = image[0]\n",
    "            image = image.permute(1, 2, 0).cpu().numpy()\n",
    "            reconstructed = reconstructed[0]\n",
    "            reconstructed = reconstructed.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "            # Convertir a formato HUE (HSV)\n",
    "            hsv_orig = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            hsv_rec = cv2.cvtColor(reconstructed, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "            # Calcular F_red para la imagen original y la reconstrucción\n",
    "            h_orig = hsv_orig[:, :, 0]\n",
    "            h_rec = hsv_rec[:, :, 0]\n",
    "\n",
    "            mask_orig = ((h_orig >= 160) & (h_orig <= 179)) | (h_orig >= 0) & (h_orig <= 20)\n",
    "            mask_rec = ((h_rec >= 160) & (h_rec <= 179)) | (h_rec >= 0) & (h_rec <= 20)\n",
    "\n",
    "            fred = np.sum(mask_orig) / max(np.sum(mask_rec), 1)\n",
    "\n",
    "            # Almacenar valores y etiquetas reales\n",
    "            fred_values.append(fred)\n",
    "\n",
    "    return fred_values\n",
    "\n",
    "# Calcular F_red para las imágenes de densidad 0\n",
    "#fred_values = get_fred(model, dataloader_annotated, device=\"cpu\")\n",
    "#print('len fred',len(fred_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "P9O0bio_SHcM"
   },
   "outputs": [],
   "source": [
    "def load_holdout_dataset(data_dir, transform=None):\n",
    "    \"\"\"\n",
    "    Carga el dataset de holdout desde un directorio especificado.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Directorio con los datos del conjunto holdout.\n",
    "        transform (torchvision.transforms.Compose): Transformaciones para aplicar a las imágenes.\n",
    "\n",
    "    Returns:\n",
    "        Dataset: Dataset PyTorch listo para usarse.\n",
    "    \"\"\"\n",
    "    if transform is None:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),  # Ajustar a la entrada del modelo\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    holdout_dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "    return holdout_dataset\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Genera un gráfico de matriz de confusión.\n",
    "\n",
    "    Args:\n",
    "        cm (ndarray): Matriz de confusión.\n",
    "        class_names (list): Nombres de las clases.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.ylabel('Etiqueta Real')\n",
    "    plt.xlabel('Etiqueta Predicha')\n",
    "    plt.title('Matriz de Confusión')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kItord7Blai4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def init_weights_transformer(module,InitParams):\n",
    "    Type=InitParams['Type']\n",
    "    U=InitParams['U']\n",
    "\n",
    "    if Type=='ori':\n",
    "        init_weights_transformer_ori(module)\n",
    "    elif Type=='all':\n",
    "        init_weights_transformer_all(module,U)\n",
    "    else:\n",
    "        init_weights_transformer_exceptnorm(module,U)\n",
    "\n",
    "def init_weights_transformer_all(module,U=[0,1]):\n",
    "    param=module.state_dict()\n",
    "\n",
    "    for name in param.keys():\n",
    "        if name.find('norm')<0:\n",
    "           nn.init.uniform_(param[name],a=U[0],b=U[1])\n",
    "\n",
    "\n",
    "def init_weights_transformer_exceptnorm(module,U=[0,1]):\n",
    "    param=module.state_dict()\n",
    "\n",
    "    for name in param.keys():\n",
    "        if name.find('norm')<0:\n",
    "           if (name.find('weight')>0):\n",
    "                nn.init.uniform_(param[name],a=U[0],b=U[1])\n",
    "           elif (name.find('bias')>0):\n",
    "                nn.init.constant_(param[name], 0)\n",
    "    #\n",
    "def init_weights_transformer_ori(module):\n",
    "    initrange = 0.1\n",
    "    nn.init.uniform_(module.encoder.weight, -initrange, initrange)\n",
    "    nn.init.zeros_(module.decoder1[0].bias)\n",
    "    nn.init.zeros_(module.decoder2.bias)\n",
    "    nn.init.uniform_(module.decoder1[0].weight, -initrange, initrange)\n",
    "    nn.init.uniform_(module.decoder2.weight, -initrange, initrange)\n",
    "\n",
    "\n",
    "def init_weights_xavier_normal(module):\n",
    "    for m in module.modules():\n",
    "        if isinstance(m, nn.Conv1d):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Conv3d):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm1d):\n",
    "            nn.init.normal_(m.weight, 0, 0.01)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.normal_(m.weight, 0, 0.01)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm3d):\n",
    "            nn.init.normal_(m.weight, 0, 0.01)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LSTM):\n",
    "            for param in m.parameters():\n",
    "                if len(param.shape) >= 2:\n",
    "                    nn.init.orthogonal_(param.data)\n",
    "                else:\n",
    "                    nn.init.normal_(param.data)\n",
    "\n",
    "def init_weights_xavier_uniform(module):\n",
    "    for m in module.modules():\n",
    "        if isinstance(m, nn.Conv1d):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Conv3d):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm1d):\n",
    "            nn.init.uniform_(m.weight, a=0, b=1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.uniform_(m.weight, a=0, b=1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm3d):\n",
    "            nn.init.uniform_(m.weight, a=0, b=1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LSTM):\n",
    "            for param in m.parameters():\n",
    "                if len(param.shape) >= 2:\n",
    "                    nn.init.orthogonal_(param.data)\n",
    "                else:\n",
    "                    nn.init.uniform_(param.data)\n",
    "\n",
    "def init_weights_kaiming_uniform(module):\n",
    "    for m in module.modules():\n",
    "        if isinstance(m, nn.Conv1d):\n",
    "            nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Conv3d):\n",
    "            nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm1d):\n",
    "            nn.init.uniform_(m.weight, a=0, b=1)\n",
    "            nn.init.constant_(m.bias, val=0.)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.uniform_(m.weight, a=0, b=1)\n",
    "            nn.init.constant_(m.bias, val=0.)\n",
    "        elif isinstance(m, nn.BatchNorm3d):\n",
    "            nn.init.uniform_(m.weight, a=0, b=1)\n",
    "            nn.init.constant_(m.bias, val=0.)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, val=0.)\n",
    "\n",
    "def init_weights_kaiming_normal(module):\n",
    "    for m in module.modules():\n",
    "        if isinstance(m, nn.Conv1d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        if isinstance(m, nn.Conv3d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm1d):\n",
    "            nn.init.normal_(m.weight, 0, 0.01)\n",
    "            nn.init.constant_(m.bias, val=0.)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.normal_(m.weight, 0, 0.01)\n",
    "            nn.init.constant_(m.bias, val=0.)\n",
    "        elif isinstance(m, nn.BatchNorm3d):\n",
    "            nn.init.normal_(m.weight, 0, 0.01)\n",
    "            nn.init.constant_(m.bias, val=0.)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, val=0.)\n",
    "\n",
    "### Linear FC Blocks\n",
    "def linear_block(n_inputs_loc, hidden_loc,\n",
    "                 activ_config=None,batch_config=None,p_drop_loc=0.1):\n",
    "\n",
    "    # Dictionary defining Block Architecture\n",
    "    BlockArchitecture=[]\n",
    "\n",
    "    hidden_loc.insert(0,n_inputs_loc)\n",
    "\n",
    "    if activ_config==None:\n",
    "        activ_config=repmat('no_activ',len(hidden_loc),1)\n",
    "    if batch_config==None:\n",
    "        batch_config=repmat('no_batch',len(hidden_loc),1)\n",
    "    #Block Layers List\n",
    "    for i in np.arange(len(hidden_loc)-1):\n",
    "        BlockArchitecture.append(('linear'+str(i+1),\n",
    "                                  nn.Linear(hidden_loc[i], hidden_loc[i+1])))\n",
    "\n",
    "        if(activ_config[i]=='relu'):\n",
    "            BlockArchitecture.append(('relu'+str(i+1),nn.ReLU(inplace=True)))\n",
    "\n",
    "        elif(activ_config[i]=='tanh'):\n",
    "            BlockArchitecture.append(('tanh'+str(i+1),nn.Tanh()))\n",
    "        elif(activ_config[i]=='relu6'):\n",
    "             BlockArchitecture.append(('relu6'+str(i+1),nn.ReLU6(inplace=True)))\n",
    "\n",
    "        if(batch_config[i]=='batch'):\n",
    "            BlockArchitecture.append(('batch'+str(i+1),nn.BatchNorm1d( hidden_loc[i+1])))\n",
    "\n",
    "        BlockArchitecture.append(('drop'+str(i+1),nn.Dropout(p_drop_loc)))\n",
    "    linear_block_loc = nn.Sequential(\n",
    "        OrderedDict(BlockArchitecture)\n",
    "        )\n",
    "    return linear_block_loc\n",
    "\n",
    "\n",
    "class LinearBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    MultiLayer Perceptron:\n",
    "    Netwotk with n_hidden layers with architecture linear+drop+relu+batch\n",
    "     Constructor Parameters:\n",
    "           n_inputs: dimensionality of input features (n_channels * n_features , by default)\n",
    "                     n_channels (=14), number of sensors or images for each case\n",
    "                     n_features(=40), number of features for each n_channels\n",
    "           n_classes: number of output classes (=3, by default)\n",
    "           hidden(=[128,128], default): list with the number of neurons for each hidden layer\n",
    "           p_drop(=0.1, default): probability for Drop layer (=0, no drop is performed)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inputmodule_params,net_params):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "\n",
    "        ### Input Parameters\n",
    "        self.n_inputs = inputmodule_params['n_inputs']\n",
    "\n",
    "\n",
    "        self.hidden=net_params['hidden']\n",
    "        self.dropout=net_params['dropout']\n",
    "        if net_params['dropout'] is None:\n",
    "            self.dropout=0.5\n",
    "        self.nlayers=len(self.hidden)\n",
    "        if 'activ_config' not in list(net_params.keys()):\n",
    "\n",
    "            self.activ_config=None\n",
    "        else:\n",
    "             self.activ_config=net_params['activ_config']\n",
    "\n",
    "        if 'batch_config' not in list(net_params.keys()):\n",
    "            self.batch_config=None\n",
    "        else:\n",
    "            self.batch_config=net_params['batch_config']\n",
    "\n",
    "\n",
    "\n",
    "        self.linear_block0= linear_block(self.n_inputs, self.hidden.copy(),\n",
    "                                                 activ_config=self.activ_config,\n",
    "                                                 batch_config=self.batch_config,\n",
    "                                                 p_drop_loc=self.dropout)\n",
    "\n",
    "\n",
    "\n",
    "      #  self.fc_out=nn.Identity()\n",
    "        # weight init\n",
    "        init_weights_xavier_normal(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "        return self.linear_block0(x)\n",
    "\n",
    "### Convolutional\n",
    "class _CNNLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_input_features: int, n_neurons: int, kernel_sze:int =3,\n",
    "        stride:int=1,\n",
    "        drop_rate: float=0,\n",
    "        Relu=True\n",
    "         ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        norm1 = nn.BatchNorm2d(n_neurons)\n",
    "        conv1 = nn.Conv2d(num_input_features, n_neurons, kernel_size=kernel_sze,\n",
    "                               stride=stride, padding=(int((kernel_sze-1)/2)))\n",
    "\n",
    "      #  relu1 = nn.ReLU(inplace=True)\n",
    "        relu1= nn.LeakyReLU(inplace=True)\n",
    "\n",
    "        drop=nn.Dropout(drop_rate)\n",
    "        if Relu:\n",
    "            self.cnn_layer=nn.Sequential(conv1,norm1,relu1,drop)\n",
    "        else:\n",
    "            self.cnn_layer=nn.Sequential(conv1,norm1,drop)\n",
    "        init_weights_xavier_normal(self)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "\n",
    "        return(self.cnn_layer(x))\n",
    "\n",
    "class _UnCNNLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self, num_input_features: int, n_neurons: int, kernel_sze:int =3,\n",
    "        stride:int=2,\n",
    "        drop_rate: float=0,\n",
    "        Relu=True\n",
    "         ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.stride=stride\n",
    "        norm1 = nn.BatchNorm2d(n_neurons)\n",
    "        conv1 = nn.ConvTranspose2d(num_input_features, n_neurons, kernel_size=kernel_sze,\n",
    "                               stride=stride, padding=(int((kernel_sze-1)/2)))\n",
    "\n",
    "\n",
    "     #   relu1 = nn.ReLU(inplace=True)\n",
    "        relu1 = nn.LeakyReLU(inplace=True)\n",
    "\n",
    "        drop=nn.Dropout(drop_rate)\n",
    "        if Relu:\n",
    "            self.cnn_layer=nn.Sequential(conv1,norm1,relu1,drop)\n",
    "        else:\n",
    "            self.cnn_layer=nn.Sequential(conv1,norm1,drop)\n",
    "        init_weights_xavier_normal(self)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "\n",
    "        if  self.stride>1:\n",
    "            sze_enc=x.shape[-1]\n",
    "            x=self.cnn_layer[0](x,output_size=(sze_enc*2,sze_enc*2))\n",
    "            for k in np.arange(1,len(self.cnn_layer)):\n",
    "                x=self.cnn_layer[k](x)\n",
    "        else:\n",
    "            x=self.cnn_layer(x)\n",
    "\n",
    "        return(x)\n",
    "\n",
    "    # def forward(self, x1, x2):\n",
    "    #     x1 = self.cnn_layer(x1)\n",
    "    #     # input is CHW\n",
    "    #     diffY = x2.size()[2] - x1.size()[2]\n",
    "    #     diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "    #     x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "    #                     diffY // 2, diffY - diffY // 2])\n",
    "    #     # if you have padding issues, see\n",
    "    #     # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "    #     # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "    #     x = torch.cat([x2, x1], dim=1)\n",
    "    #     return self.conv(x)\n",
    "\n",
    "class _CNNBlock(nn.ModuleDict):\n",
    "    _version = 2\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_input_channels: int=1,\n",
    "        drop_rate=0,\n",
    "        block_config = (64,128),\n",
    "        stride=None,\n",
    "        decoder=False,\n",
    "        Relu=True\n",
    "\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        num_layers=len(block_config)\n",
    "        self.num_input_channels=num_input_channels\n",
    "        print('block inp ch',num_input_channels)\n",
    "\n",
    "        if stride is None:\n",
    "            stride=np.ones(num_layers)\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            if decoder==True:\n",
    "                layer = _UnCNNLayer(\n",
    "                    num_input_channels,\n",
    "                    n_neurons=block_config[i],\n",
    "                    stride=stride[i],\n",
    "                    drop_rate=drop_rate\n",
    "\n",
    "                )\n",
    "            else:\n",
    "                layer = _CNNLayer(\n",
    "                    num_input_channels,\n",
    "                    n_neurons=block_config[i],\n",
    "                    stride=stride[i],\n",
    "                    drop_rate=drop_rate,\n",
    "                    Relu=Relu\n",
    "\n",
    "                )\n",
    "            self.add_module(\"cnnlayer%d\" % (i + 1), layer)\n",
    "            num_input_channels=block_config[i]\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "\n",
    "        for name, layer in self.items():\n",
    "            x = layer(x)\n",
    "\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "G5RvhTm0kCn4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    r\"\"\"Encoder class\n",
    "    `\".\n",
    "    Input Parameters:\n",
    "        1. inputmodule_params: dictionary with keys ['num_input_channels']\n",
    "            inputmodule_params['num_input_channels']=Channels of input images\n",
    "        2. net_params: dictionary defining architecture:\n",
    "            net_params['block_configs']: list of number of neurons for each\n",
    "            convolutional block. A block can have more than one layer\n",
    "            net_params['stride']:list of strides for each block layers\n",
    "            net_params['drop_rate']: value of the Dropout (equal for all blocks)\n",
    "        Examples:\n",
    "            1. Encoder with 4 blocks with one layer each\n",
    "            net_params['block_configs']=[[32],[64],[128],[256]]\n",
    "            net_params['stride']=[[2],[2],[2],[2]]\n",
    "            2. Encoder with 2 blocks with two layers each\n",
    "            net_params['block_configs']=[[32,32],[64,64]]\n",
    "            net_params['stride']=[[1,2],[1,2]]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inputmodule_params,net_params):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        num_input_channels=inputmodule_params['num_input_channels']\n",
    "\n",
    "\n",
    "\n",
    "        drop_rate=net_params['drop_rate']\n",
    "        block_configs=net_params['block_configs'].copy()\n",
    "        n_blocks=len(block_configs)\n",
    "        if 'stride' in net_params.keys():\n",
    "            stride=net_params['stride']\n",
    "        else:\n",
    "            stride=[]\n",
    "            for i in np.arange(len(block_configs)):\n",
    "                stride.append(list(np.ones(len(block_configs[i])-1,dtype=int))+[2])\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder=nn.Sequential(\n",
    "            )\n",
    "        outchannels_encoder=[]\n",
    "        for i in np.arange(n_blocks):\n",
    "            print('block',i)\n",
    "            block = _CNNBlock(\n",
    "                num_input_channels=num_input_channels,\n",
    "                drop_rate=drop_rate,\n",
    "                block_config=block_configs[i],\n",
    "                stride= stride[i]\n",
    "\n",
    "            )\n",
    "            self.encoder.add_module(\"cnnblock%d\" % (i + 1), block)\n",
    "\n",
    "            if stride==1:\n",
    "                self.encoder.add_module(\"mxpool%d\" % (i + 1),\n",
    "                                         nn.MaxPool2d(kernel_size=2, stride=2, padding=0))\n",
    "\n",
    "            num_input_channels=block_configs[i][-1]\n",
    "           # outchannels_encoder.append(num_input_channels)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "\n",
    "        x=self.encoder(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    r\"\"\"Decoder class\n",
    "    `\".\n",
    "    Input Parameters:\n",
    "        1. inputmodule_params: dictionary with keys ['num_input_channels']\n",
    "            inputmodule_params['num_input_channels']=Channels of input images\n",
    "        2. net_params: dictionary defining architecture:\n",
    "            net_params['block_configs']: list of number of neurons for each conv block\n",
    "            net_params['stride']:list of strides for each block layers\n",
    "            net_params['drop_rate']: value of the Dropout (equal for all blocks)\n",
    "    \"\"\"\n",
    "    def __init__(self, inputmodule_params,net_params):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        num_input_channels=inputmodule_params['num_input_channels']\n",
    "\n",
    "        self.upPoolMode='bilinear'\n",
    "\n",
    "\n",
    "        drop_rate=net_params['drop_rate']\n",
    "        block_configs=net_params['block_configs'].copy()\n",
    "        self.n_blocks=len(block_configs)\n",
    "\n",
    "        if 'stride' in net_params.keys():\n",
    "            stride=net_params['stride']\n",
    "        else:\n",
    "            stride=[]\n",
    "            for i in np.arange(len(block_configs)):\n",
    "                stride.append(list(np.ones(len(block_configs[i])-1,dtype=int))+[2])\n",
    "\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder=nn.Sequential(\n",
    "            )\n",
    "\n",
    "        for i0 in np.arange(self.n_blocks)[::-1]:\n",
    "            i=self.n_blocks-(i0+1)\n",
    "            block = _CNNBlock(\n",
    "                num_input_channels=num_input_channels,\n",
    "                drop_rate=drop_rate,\n",
    "                block_config=block_configs[i],\n",
    "                stride=stride[i],\n",
    "                decoder=True\n",
    "            )\n",
    "\n",
    "            # if stride==1:\n",
    "            #     self.decoder.add_module(\"uppool%d\" % (i + 1),\n",
    "            #                               nn.Upsample(scale_factor=2,\n",
    "            #                                           mode=self.upPoolMode, align_corners=True))\n",
    "\n",
    "            self.decoder.add_module(\"cnnblock%d\" % (i0+1), block)\n",
    "\n",
    "\n",
    "            num_input_channels=block_configs[i][-1]\n",
    "\n",
    "\n",
    "        self.decoder[-1][list(self.decoder[-1].keys())[-1]].cnn_layer[2]=nn.Identity()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "\n",
    "        input_sze=x.shape\n",
    "\n",
    "     #   for i in np.arange(n_blocks)[::-1]:\n",
    "\n",
    "        x=self.decoder(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "##### GENERATIVE MODELS\n",
    "class AutoEncoderCNN(nn.Module):\n",
    "    r\"\"\"AutoEncoderCNN model class\n",
    "    `\".\n",
    "    Input Parameters:\n",
    "        1. inputmodule_paramsEnc: dictionary with keys ['num_input_channels']\n",
    "            inputmodule_paramsEnc['num_input_channels']=Channels of input images\n",
    "        2. net_paramsEnc: dictionary defining architecture of the Encoder (see Encoder class)\n",
    "        3. inputmodule_paramsDec: dictionary with keys ['num_input_channels']\n",
    "           inputmodule_paramsDec['num_input_channels']=Channels of input images\n",
    "        4. net_paramsDec: dictionary defining architecture of the Encoder (see Decoder/Encoder classes)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inputmodule_paramsEnc,net_paramsEnc,inputmodule_paramsDec,net_paramsDec):\n",
    "        super().__init__()\n",
    "\n",
    "        self.inputmodule_paramsEnc=inputmodule_paramsEnc\n",
    "        self.inputmodule_paramsDec=inputmodule_paramsDec\n",
    "        self.net_paramsEnc=net_paramsEnc\n",
    "        self.net_paramsDec=net_paramsDec\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder=Encoder(inputmodule_paramsEnc,net_paramsEnc)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder=Decoder(inputmodule_paramsDec,net_paramsDec)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "            # Guardamos el tamaño de la imagen de entrada para usarlo al final (en la fase de upsampling)\n",
    "            input_size = x.shape\n",
    "\n",
    "            # Paso por el Encoder\n",
    "            encoded = self.encoder(x)\n",
    "\n",
    "            # Paso por el Decoder\n",
    "            decoded = self.decoder(encoded)\n",
    "\n",
    "            return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DnXNvwoIlBRq"
   },
   "outputs": [],
   "source": [
    "def AEConfigs(Config):\n",
    "\n",
    "    if Config=='1':\n",
    "        # CONFIG1\n",
    "        net_paramsEnc['block_configs']=[[32,32],[64,64]]\n",
    "        net_paramsEnc['stride']=[[1,2],[1,2]]\n",
    "        net_paramsEnc['drop_rate']=0.1\n",
    "        net_paramsDec['drop_rate']=0.1\n",
    "        net_paramsDec['block_configs']=[[64,32],[32,inputmodule_paramsEnc['num_input_channels']]]\n",
    "        net_paramsDec['stride']=net_paramsEnc['stride']\n",
    "        inputmodule_paramsDec['num_input_channels']=net_paramsEnc['block_configs'][-1][-1]\n",
    "\n",
    "\n",
    "\n",
    "    elif Config=='2':\n",
    "        # CONFIG 2\n",
    "        net_paramsEnc['block_configs']=[[32],[64],[128],[256]]\n",
    "        net_paramsEnc['stride']=[[2],[2],[2],[2]]\n",
    "        net_paramsDec['block_configs']=[[128],[64],[32],[inputmodule_paramsEnc['num_input_channels']]]\n",
    "        net_paramsDec['stride']=net_paramsEnc['stride']\n",
    "        inputmodule_paramsDec['num_input_channels']=net_paramsEnc['block_configs'][-1][-1]\n",
    "\n",
    "\n",
    "    elif Config=='3':\n",
    "        # CONFIG3\n",
    "        net_paramsEnc['block_configs']=[[32],[64],[64]]\n",
    "        net_paramsEnc['stride']=[[1],[2],[2]]\n",
    "        net_paramsDec['block_configs']=[[64],[32],[inputmodule_paramsEnc['num_input_channels']]]\n",
    "        net_paramsDec['stride']=net_paramsEnc['stride']\n",
    "        inputmodule_paramsDec['num_input_channels']=net_paramsEnc['block_configs'][-1][-1]\n",
    "\n",
    "    return net_paramsEnc,net_paramsDec,inputmodule_paramsDec\n",
    "\n",
    "\n",
    "######################### 0. EXPERIMENT PARAMETERS\n",
    "\n",
    "# 0.2 Parámetros y definiciones de red\n",
    "inputmodule_paramsEnc = {'num_input_channels': 3}\n",
    "net_paramsEnc = {}\n",
    "net_paramsDec = {}\n",
    "inputmodule_paramsDec = {}\n",
    "\n",
    "# 0.1 AE PARAMETERS\n",
    "inputmodule_paramsEnc={}\n",
    "inputmodule_paramsEnc['num_input_channels']=3\n",
    "\n",
    "###### CONFIG1\n",
    "Config='1'\n",
    "net_paramsEnc,net_paramsDec,inputmodule_paramsDec=AEConfigs(Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5p30a4ayiikX",
    "outputId": "eb3fad97-f79f-41e2-f8a7-e8f270f367f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block 0\n",
      "block inp ch 3\n",
      "block 1\n",
      "block inp ch 32\n",
      "block inp ch 64\n",
      "block inp ch 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model = AutoEncoderCNN(inputmodule_paramsEnc, net_paramsEnc,\n",
    "                     inputmodule_paramsDec, net_paramsDec)\n",
    "model.load_state_dict(torch.load('best_model_AECNN3_50.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YtKUt85YkhqI",
    "outputId": "0ff80186-c3a8-4dcb-cb08-b6cbd8b97c6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoderCNN(\n",
      "  (encoder): Encoder(\n",
      "    (encoder): Sequential(\n",
      "      (cnnblock1): _CNNBlock(\n",
      "        (cnnlayer1): _CNNLayer(\n",
      "          (cnn_layer): Sequential(\n",
      "            (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (cnnlayer2): _CNNLayer(\n",
      "          (cnn_layer): Sequential(\n",
      "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (cnnblock2): _CNNBlock(\n",
      "        (cnnlayer1): _CNNLayer(\n",
      "          (cnn_layer): Sequential(\n",
      "            (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (cnnlayer2): _CNNLayer(\n",
      "          (cnn_layer): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (decoder): Sequential(\n",
      "      (cnnblock2): _CNNBlock(\n",
      "        (cnnlayer1): _UnCNNLayer(\n",
      "          (cnn_layer): Sequential(\n",
      "            (0): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (cnnlayer2): _UnCNNLayer(\n",
      "          (cnn_layer): Sequential(\n",
      "            (0): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (cnnblock1): _CNNBlock(\n",
      "        (cnnlayer1): _UnCNNLayer(\n",
      "          (cnn_layer): Sequential(\n",
      "            (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
      "            (3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (cnnlayer2): _UnCNNLayer(\n",
      "          (cnn_layer): Sequential(\n",
      "            (0): ConvTranspose2d(32, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "            (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Identity()\n",
      "            (3): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5-wZsPDMwg9S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized images: 0/116\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "def load_cropped(folder_path, csv_path, patient_list = [], sample_size=200, prints = False):\n",
    "    # Cargar el CSV con pandas\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Convertir el CSV a un diccionario para un acceso rápido\n",
    "    patient_metadata = {row['CODI']: row['DENSITAT'] for _, row in df.iterrows()}\n",
    "\n",
    "    # Inicializar la estructura de datos para almacenar los datos de los pacientes seleccionados\n",
    "    patients_data = []\n",
    "    images_list = []\n",
    "    patients_list_img = []\n",
    "\n",
    "    # si no se proporciona una lista de pacientes, se seleccionan todos los pacientes iterando folder_path\n",
    "    if len(patient_list) == 0:\n",
    "        for patient_folder in glob.glob(os.path.join(folder_path, \"*\")):\n",
    "            patient_id = os.path.basename(patient_folder).split(\"_\")[0]\n",
    "            patient_list.append(patient_id)\n",
    "\n",
    "    incorrect_shape = 0\n",
    "    # Iterar sobre cada paciente en la lista de IDs proporcionada\n",
    "    for i,patient_id in enumerate(patient_list):\n",
    "        # Obtener carpeta del paciente\n",
    "        try:\n",
    "            patient_folder = glob.glob(os.path.join(folder_path, f\"{patient_id}_*\"))[0]\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Verificar que el paciente esté en el CSV\n",
    "        if patient_id in patient_metadata:\n",
    "            # Obtener todas las imágenes .png dentro de la carpeta del paciente\n",
    "            images = glob.glob(os.path.join(patient_folder, \"*.png\"))\n",
    "\n",
    "            # Si el paciente tiene imágenes en su carpeta\n",
    "            if images:\n",
    "                # Mezclar la lista de imágenes\n",
    "                random.shuffle(images)\n",
    "\n",
    "                if sample_size == -1:\n",
    "                    sample_size = len(images)\n",
    "                # Seleccionar una muestra de tamaño sample_size o menos si hay menos imágenes\n",
    "                images_sampled = random.sample(images, min(sample_size, len(images)))\n",
    "\n",
    "                for j,image_path in enumerate(images_sampled):\n",
    "                    if j % 200 == 0:\n",
    "                        if prints:\n",
    "                            print(f\"Processing patient {i+1}/{len(patient_list)} - image {j+1}/{len(images_sampled)}\")\n",
    "\n",
    "                    # Cargar la imagen en formato BGR con cv2\n",
    "                    image_bgr = cv2.imread(image_path)\n",
    "\n",
    "                    # Convertir la imagen de BGR a RGB\n",
    "                    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                    if image_rgb.shape[0] != 256 or image_rgb.shape[1] != 256:\n",
    "                        incorrect_shape +=1\n",
    "                        # Resize de la imagen a 256x256\n",
    "                        image_rgb = cv2.resize(image_rgb, (256, 256))\n",
    "\n",
    "                    # Permutar canales\n",
    "                    image_rgb = np.transpose(image_rgb, (2, 0, 1))\n",
    "\n",
    "                    # Pasar de uint8 a float32\n",
    "                    image_rgb = image_rgb/255.0\n",
    "\n",
    "                    # Añadir la imagen a la lista de imágenes en formato RGB\n",
    "                    images_list.append(image_rgb)\n",
    "                # Binariar densidad\n",
    "                if patient_metadata[patient_id] == \"NEGATIVA\":\n",
    "                    dens = 0\n",
    "                else:\n",
    "                    dens = 1\n",
    "\n",
    "                # Añadir la densidad a la lista de metadatos\n",
    "                patients_data.extend([dens] * len(images_sampled))\n",
    "                patients_list_img.extend([patient_id] * len(images_sampled))\n",
    "\n",
    "    print(f'Resized images: {incorrect_shape}/{len(images_list)}')\n",
    "\n",
    "    return images_list, patients_data, patients_list_img\n",
    "\n",
    "# Paso 2: Crear la clase Standard_Dataset\n",
    "class Standard_Dataset(data.Dataset):\n",
    "    def __init__(self, X, Y=None, transformation=None):\n",
    "        super().__init__()\n",
    "        self.X = X\n",
    "        self.y = Y\n",
    "        self.transformation = transformation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx]\n",
    "        if self.transformation:\n",
    "            image = self.transformation(image)\n",
    "\n",
    "        image_tensor = torch.from_numpy(image).float()\n",
    "\n",
    "        if self.y is not None:\n",
    "            label = torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "            return image_tensor, label\n",
    "        else:\n",
    "            return image_tensor\n",
    "\n",
    "# Paso 3: Cargar los datos\n",
    "folder_path = \"HoldOut\"\n",
    "csv_path = \"PatientDiagnosis.csv\"\n",
    "patient_list = []\n",
    "sample_size = 1\n",
    "\n",
    "# Filtrando imágenes y etiquetas para obtener solo aquellas cuya densidad es 0\n",
    "images, labels, pat_list_img = load_cropped(folder_path, csv_path, patient_list, sample_size)\n",
    "dataset_holdour = Standard_Dataset(images)\n",
    "dataloader_holder = DataLoader(dataset_holdour, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_holdour = Standard_Dataset(images)\n",
    "dataloader_holder = DataLoader(dataset_holdour, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "E556sUYRlfr6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len fred 116\n",
      "[2.0, 2.0, 0.0, 9.0, 27.0, 64.0, 0.0, 37.0, 102.0, 31.0, 0.0, 579.0, 94.0, 66.0, 116.0, 506.0, 538.0, 696.0, 8.0, 21.0, 1720.0, 6.0, 0.0, 0.0, 4.0, 150.0, 0.0, 49.0, 0.0, 0.0, 98.0, 247.0, 109.0, 21.0, 160.0, 12.0, 1.0, 5.0, 95.0, 0.0, 44.0, 47.0, 0.0, 0.0, 5.0, 0.0, 2.0, 4.0, 109.0, 1.0, 0.0, 2.0, 0.0, 87.0, 1.0, 0.0, 2648.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 1.0, 0.0, 0.0, 14.0, 0.0, 0.0, 0.0, 1.0, 4.0, 48.0, 0.0, 13.0, 4.0, 0.0, 8.0, 1.0, 25.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 429.0, 146.0, 4.0, 487.0, 17.0, 1.0, 2.0, 295.0, 0.0, 4.0, 101.0, 371.0, 2.0, 4974.0, 10.0, 16.0, 6.0, 18.0, 0.0, 0.0, 12.0, 3012.0, 0.0, 46.0, 0.0, 0.0, 2.0, 34.0]\n"
     ]
    }
   ],
   "source": [
    "fred_values = get_fred(model, dataloader_holder, device=\"cpu\")\n",
    "print('len fred',len(fred_values))\n",
    "print(fred_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_FRED_threshold(fred_values, patch_threshold_fred):\n",
    "    img_positive = np.array(fred_values) >= patch_threshold_fred\n",
    "    return img_positive\n",
    "\n",
    "def classify_PATIENT_threshold(fred_values, patient_val, patient_image_list, patch_threshold_fred, patient_threshold_fred):\n",
    "    img_positive = classify_FRED_threshold(fred_values, patch_threshold_fred)\n",
    "    unique_patients = np.unique(patient_val)\n",
    "    patient_positive_counts = []\n",
    "\n",
    "    for patient_id in unique_patients:\n",
    "        patient_indices = np.where(np.array(patient_image_list) == patient_id)[0]\n",
    "        patient_positive_counts.append(np.sum(img_positive[patient_indices])/ len(patient_indices))\n",
    "\n",
    "    patient_positive = np.array(patient_positive_counts) >= patient_threshold_fred\n",
    "\n",
    "    return patient_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La media de los valores en la columna 'threshold' es: 107.4\n",
      "La media de los valores en la columna 'threshold' es: 0.20999999999999996\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el CSV\n",
    "csv_path = \"patches_thresholds.csv\"  # Asegúrate de que el nombre del archivo sea correcto\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# Calcular la media de la columna 'threshold'\n",
    "patches_mean_threshold = data['threshold'].mean()\n",
    "\n",
    "print(f\"La media de los valores en la columna 'threshold' es: {patches_mean_threshold}\")\n",
    "\n",
    "# Cargar el CSV\n",
    "csv_path = \"patient_thresholds.csv\"  # Asegúrate de que el nombre del archivo sea correcto\n",
    "data = pd.read_csv(csv_path)\n",
    "\n",
    "# Calcular la media de la columna 'threshold'\n",
    "patient_mean_threshold = data['threshold'].mean()\n",
    "\n",
    "print(f\"La media de los valores en la columna 'threshold' es: {patient_mean_threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marbj\\AppData\\Local\\Temp\\ipykernel_8716\\679301622.py:11: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  patient_indices = np.where(np.array(patient_image_list) == patient_id)[0]\n",
      "C:\\Users\\marbj\\AppData\\Local\\Temp\\ipykernel_8716\\679301622.py:12: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  patient_positive_counts.append(np.sum(img_positive[patient_indices])/ len(patient_indices))\n"
     ]
    }
   ],
   "source": [
    "patient_positive = classify_PATIENT_threshold(fred_values, images, pat_list_img, patches_mean_threshold, patient_mean_threshold)\n",
    "print(patient_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calcular_media(data):\n",
    "    return data['threshold'].mean()\n",
    "\n",
    "def calcular_mediana(data):\n",
    "    return data['threshold'].median()\n",
    "\n",
    "def calcular_desviacion_estandar(data):\n",
    "    return data['threshold'].std()\n",
    "\n",
    "def calcular_minimo(data):\n",
    "    return data['threshold'].min()\n",
    "\n",
    "def calcular_maximo(data):\n",
    "    return data['threshold'].max()\n",
    "\n",
    "def calcular_cuartiles(data):\n",
    "    q1 = data['threshold'].quantile(0.25)\n",
    "    q3 = data['threshold'].quantile(0.75)\n",
    "    return q1, q3\n",
    "\n",
    "def calcular_varianza(data):\n",
    "    return data['threshold'].var()\n",
    "\n",
    "def resumen_descriptivo(data):\n",
    "    return data['threshold'].describe()\n",
    "\n",
    "def normalizar(data):\n",
    "    min_val = data['threshold'].min()\n",
    "    max_val = data['threshold'].max()\n",
    "    data['normalized_threshold'] = (data['threshold'] - min_val) / (max_val - min_val)\n",
    "    return data\n",
    "\n",
    "def calcular_embedding(data):\n",
    "    return np.mean(data['threshold'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media: 107.4\n",
      "Mediana: 107.0\n",
      "Minimo: 101\n",
      "Maximo: 113\n",
      "Cuartiles: Q1=104.0, Q3=112.0\n",
      "107.4\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('patches_thresholds.csv')\n",
    "\n",
    "media = calcular_media(data)\n",
    "mediana = calcular_mediana(data)\n",
    "std_dev = calcular_desviacion_estandar(data)\n",
    "q1, q3 = calcular_cuartiles(data)\n",
    "varianza = calcular_varianza(data)\n",
    "normalizado = normalizar(data)\n",
    "embedding = calcular_embedding(data)\n",
    "minimo = calcular_minimo(data)\n",
    "maximo = calcular_maximo(data)\n",
    "\n",
    "print(f\"Media: {media}\")\n",
    "print(f\"Mediana: {mediana}\")\n",
    "print(f\"Minimo: {minimo}\")\n",
    "print(f\"Maximo: {maximo}\")\n",
    "#print(f\"Desviación estándar: {std_dev}\")\n",
    "print(f\"Cuartiles: Q1={q1}, Q3={q3}\")\n",
    "#print(f\"Varianza: {varianza}\")\n",
    "#print(\"Datos normalizados:\")\n",
    "#print(normalizado)\n",
    "print(embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métrica: fold\n",
      "  Mínimo: 0\n",
      "  Máximo: 4\n",
      "---\n",
      "Métrica: accuracy\n",
      "  Mínimo: 0.2903225806451613\n",
      "  Máximo: 0.7096774193548387\n",
      "---\n",
      "Métrica: precision\n",
      "  Mínimo: 0.3\n",
      "  Máximo: 0.7333333333333333\n",
      "---\n",
      "Métrica: recall\n",
      "  Mínimo: 0.3333333333333333\n",
      "  Máximo: 0.6875\n",
      "---\n",
      "Métrica: f1_score\n",
      "  Mínimo: 0.3157894736842105\n",
      "  Máximo: 0.7096774193548386\n",
      "---\n",
      "Métrica: tp\n",
      "  Mínimo: 3\n",
      "  Máximo: 11\n",
      "---\n",
      "Métrica: tn\n",
      "  Mínimo: 3\n",
      "  Máximo: 15\n",
      "---\n",
      "Métrica: fp\n",
      "  Mínimo: 4\n",
      "  Máximo: 12\n",
      "---\n",
      "Métrica: fn\n",
      "  Mínimo: 5\n",
      "  Máximo: 10\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "csv_path = \"metrics_th2.csv\"  # Cambia al nombre de tu archivo\n",
    "data = pd.read_csv(csv_path, delimiter=\",\")  # Usa `delimiter=\"\\t\"` si es TSV\n",
    "\n",
    "\n",
    "# Calcular el rango (mínimo y máximo) para cada columna de métricas\n",
    "def calcular_rangos(data):\n",
    "    rangos = {}\n",
    "    #print(data)\n",
    "    #print(data.columns)\n",
    "    for columna in data.columns:  # Excluir la columna `fold`\n",
    "        minimo = data[columna].min()\n",
    "        maximo = data[columna].max()\n",
    "        #print(minimo, maximo)\n",
    "        rangos[columna] = (minimo, maximo)\n",
    "    return rangos\n",
    "\n",
    "# Llamar a la función y mostrar resultados\n",
    "rangos = calcular_rangos(data)\n",
    "#print(rangos)\n",
    "\n",
    "# Imprimir los rangos\n",
    "for metrica, (min_val, max_val) in rangos.items():\n",
    "    print(f\"Métrica: {metrica}\")\n",
    "    print(f\"  Mínimo: {min_val}\")\n",
    "    print(f\"  Máximo: {max_val}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
