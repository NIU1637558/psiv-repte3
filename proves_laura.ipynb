{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPcDPLgCjMLV"
      },
      "source": [
        "# 1. Load cropped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnoi3aEqjMLa",
        "outputId": "e7a03236-fd3e-47c4-9549-7e4b3dc082fe"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'models_init'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[72], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmatlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m repmat\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels_init\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mNetBlocks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _CNNBlock,_UnCNNLayer\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'models_init'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import random\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils import data\n",
        "import numpy as np\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "import torch\n",
        "from torch import nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from numpy.matlib import repmat\n",
        "\n",
        "from models_init import *\n",
        "from NetBlocks import _CNNBlock,_UnCNNLayer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1j2pGeuEjMLe",
        "outputId": "cb8fbd5a-52f5-47b4-b706-dd6e59d7868b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1\n",
            "Datos (imágenes): torch.Size([16, 256, 256, 4])\n",
            "Etiquetas (densidad): tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.utils.data as data\n",
        "\n",
        "# Paso 1: Definir la función load_cropped\n",
        "def load_cropped(folder_path, csv_path, patient_list, sample_size=200):\n",
        "    # Cargar el CSV con pandas\n",
        "    df = pd.read_csv(csv_path)\n",
        "\n",
        "    # Convertir el CSV a un diccionario para un acceso rápido\n",
        "    patient_metadata = {row['CODI']: row['DENSITAT'] for _, row in df.iterrows()}\n",
        "\n",
        "    # Inicializar la estructura de datos para almacenar los datos de los pacientes seleccionados\n",
        "    patients_data = []\n",
        "    images_list = []\n",
        "\n",
        "    # Iterar sobre cada paciente en la lista de IDs proporcionada\n",
        "    for patient_id in patient_list:\n",
        "        # Obtener carpeta del paciente\n",
        "        patient_folder = glob.glob(os.path.join(folder_path, f\"{patient_id}_*\"))[0]\n",
        "\n",
        "        # Verificar que el paciente esté en el CSV\n",
        "        if patient_id in patient_metadata:\n",
        "            # Obtener todas las imágenes .png dentro de la carpeta del paciente\n",
        "            images = glob.glob(os.path.join(patient_folder, \"*.png\"))\n",
        "\n",
        "            # Si el paciente tiene imágenes en su carpeta\n",
        "            if images:\n",
        "                # Mezclar la lista de imágenes\n",
        "                random.shuffle(images)\n",
        "\n",
        "                # Seleccionar una muestra de tamaño sample_size o menos si hay menos imágenes\n",
        "                images_sampled = random.sample(images, min(sample_size, len(images)))\n",
        "\n",
        "                for image_path in images_sampled:\n",
        "                    # Cargar la imagen\n",
        "                    image = Image.open(image_path)\n",
        "\n",
        "                    # Convertir a numpy array\n",
        "                    image_np = np.array(image)\n",
        "\n",
        "                    # Añadir la imagen a la lista de imágenes\n",
        "                    images_list.append(image_np)\n",
        "\n",
        "                # Binariar densidad\n",
        "                if patient_metadata[patient_id] == \"NEGATIVA\":\n",
        "                    dens = 0\n",
        "                else:\n",
        "                    dens = 1\n",
        "\n",
        "                # Añadir la densidad a la lista de metadatos\n",
        "                patients_data.extend([dens] * len(images_sampled))\n",
        "\n",
        "    return images_list, patients_data\n",
        "\n",
        "# Paso 2: Crear la clase Standard_Dataset\n",
        "class Standard_Dataset(data.Dataset):\n",
        "    def __init__(self, X, Y=None, transformation=None):\n",
        "        super().__init__()\n",
        "        self.X = X\n",
        "        self.y = Y\n",
        "        self.transformation = transformation\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.X[idx]\n",
        "        if self.transformation:\n",
        "            image = self.transformation(image)\n",
        "\n",
        "        image_tensor = torch.from_numpy(image).float()\n",
        "\n",
        "        if self.y is not None:\n",
        "            label = torch.tensor(self.y[idx], dtype=torch.float32)\n",
        "            return image_tensor, label\n",
        "        else:\n",
        "            return image_tensor\n",
        "\n",
        "# Paso 3: Cargar los datos\n",
        "folder_path = \"C:/Users/mirvi/Desktop/mii/UAB/4.1/PSIV2/detect mateicules/repte3/psiv-repte3/data/Cropped_sample\"\n",
        "csv_path = \"C:/Users/mirvi/Desktop/mii/UAB/4.1/PSIV2/detect mateicules/repte3/psiv-repte3/data/PatientDiagnosis.csv\"\n",
        "patient_list = [\"B22-25\", \"B22-29\"]\n",
        "sample_size = 200\n",
        "\n",
        "images, labels = load_cropped(folder_path, csv_path, patient_list, sample_size)\n",
        "\n",
        "# Paso 4: Crear el Dataset y DataLoader\n",
        "dataset = Standard_Dataset(images, labels)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Paso 5: Probar el DataLoader\n",
        "for batch_idx, (data, target) in enumerate(dataloader):\n",
        "    print(f\"Batch {batch_idx + 1}\")\n",
        "    print(\"Datos (imágenes):\", data.shape)\n",
        "    print(\"Etiquetas (densidad):\", target)\n",
        "    if batch_idx == 0:\n",
        "        break  # Solo mostrar el primer batch para verificar que todo funciona\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNwUxdb8jMLj"
      },
      "source": [
        "## 2. AUTOENCODER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6V1E27HjMLl"
      },
      "outputs": [],
      "source": [
        "\n",
        "#  BACKBONE MODULES\n",
        "class Encoder(nn.Module):\n",
        "    r\"\"\"Encoder class\n",
        "    `\".\n",
        "    Input Parameters:\n",
        "        1. inputmodule_params: dictionary with keys ['num_input_channels']\n",
        "            inputmodule_params['num_input_channels']=Channels of input images\n",
        "        2. net_params: dictionary defining architecture:\n",
        "            net_params['block_configs']: list of number of neurons for each\n",
        "            convolutional block. A block can have more than one layer\n",
        "            net_params['stride']:list of strides for each block layers\n",
        "            net_params['drop_rate']: value of the Dropout (equal for all blocks)\n",
        "        Examples:\n",
        "            1. Encoder with 4 blocks with one layer each\n",
        "            net_params['block_configs']=[[32],[64],[128],[256]]\n",
        "            net_params['stride']=[[2],[2],[2],[2]]\n",
        "            2. Encoder with 2 blocks with two layers each\n",
        "            net_params['block_configs']=[[32,32],[64,64]]\n",
        "            net_params['stride']=[[1,2],[1,2]]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, inputmodule_params,net_params):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        num_input_channels=inputmodule_params['num_input_channels']\n",
        "\n",
        "\n",
        "\n",
        "        drop_rate=net_params['drop_rate']\n",
        "        block_configs=net_params['block_configs'].copy()\n",
        "        n_blocks=len(block_configs)\n",
        "        if 'stride' in net_params.keys():\n",
        "            stride=net_params['stride']\n",
        "        else:\n",
        "            stride=[]\n",
        "            for i in np.arange(len(block_configs)):\n",
        "                stride.append(list(np.ones(len(block_configs[i])-1,dtype=int))+[2])\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder=nn.Sequential(\n",
        "            )\n",
        "        outchannels_encoder=[]\n",
        "        for i in np.arange(n_blocks):\n",
        "            block = _CNNBlock(\n",
        "                num_input_channels=num_input_channels,\n",
        "                drop_rate=drop_rate,\n",
        "                block_config=block_configs[i],\n",
        "                stride= stride[i]\n",
        "\n",
        "            )\n",
        "            self.encoder.add_module(\"cnnblock%d\" % (i + 1), block)\n",
        "\n",
        "            if stride==1:\n",
        "                self.encoder.add_module(\"mxpool%d\" % (i + 1),\n",
        "                                         nn.MaxPool2d(kernel_size=2, stride=2, padding=0))\n",
        "\n",
        "            num_input_channels=block_configs[i][-1]\n",
        "           # outchannels_encoder.append(num_input_channels)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "\n",
        "        x=self.encoder(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    r\"\"\"Decoder class\n",
        "    `\".\n",
        "    Input Parameters:\n",
        "        1. inputmodule_params: dictionary with keys ['num_input_channels']\n",
        "            inputmodule_params['num_input_channels']=Channels of input images\n",
        "        2. net_params: dictionary defining architecture:\n",
        "            net_params['block_configs']: list of number of neurons for each conv block\n",
        "            net_params['stride']:list of strides for each block layers\n",
        "            net_params['drop_rate']: value of the Dropout (equal for all blocks)\n",
        "    \"\"\"\n",
        "    def __init__(self, inputmodule_params,net_params):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        num_input_channels=inputmodule_params['num_input_channels']\n",
        "\n",
        "        self.upPoolMode='bilinear'\n",
        "\n",
        "\n",
        "        drop_rate=net_params['drop_rate']\n",
        "        block_configs=net_params['block_configs'].copy()\n",
        "        self.n_blocks=len(block_configs)\n",
        "\n",
        "        if 'stride' in net_params.keys():\n",
        "            stride=net_params['stride']\n",
        "        else:\n",
        "            stride=[]\n",
        "            for i in np.arange(len(block_configs)):\n",
        "                stride.append(list(np.ones(len(block_configs[i])-1,dtype=int))+[2])\n",
        "\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder=nn.Sequential(\n",
        "            )\n",
        "\n",
        "        for i0 in np.arange(self.n_blocks)[::-1]:\n",
        "            i=self.n_blocks-(i0+1)\n",
        "            block = _CNNBlock(\n",
        "                num_input_channels=num_input_channels,\n",
        "                drop_rate=drop_rate,\n",
        "                block_config=block_configs[i],\n",
        "                stride=stride[i],\n",
        "                decoder=True\n",
        "            )\n",
        "\n",
        "            # if stride==1:\n",
        "            #     self.decoder.add_module(\"uppool%d\" % (i + 1),\n",
        "            #                               nn.Upsample(scale_factor=2,\n",
        "            #                                           mode=self.upPoolMode, align_corners=True))\n",
        "\n",
        "            self.decoder.add_module(\"cnnblock%d\" % (i0+1), block)\n",
        "\n",
        "\n",
        "            num_input_channels=block_configs[i][-1]\n",
        "\n",
        "\n",
        "        self.decoder[-1][list(self.decoder[-1].keys())[-1]].cnn_layer[2]=nn.Identity()\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "\n",
        "        input_sze=x.shape\n",
        "\n",
        "     #   for i in np.arange(n_blocks)[::-1]:\n",
        "\n",
        "        x=self.decoder(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "##### GENERATIVE MODELS\n",
        "class AutoEncoderCNN(nn.Module):\n",
        "    r\"\"\"AutoEncoderCNN model class\n",
        "    `\".\n",
        "    Input Parameters:\n",
        "        1. inputmodule_paramsEnc: dictionary with keys ['num_input_channels']\n",
        "            inputmodule_paramsEnc['num_input_channels']=Channels of input images\n",
        "        2. net_paramsEnc: dictionary defining architecture of the Encoder (see Encoder class)\n",
        "        3. inputmodule_paramsDec: dictionary with keys ['num_input_channels']\n",
        "           inputmodule_paramsDec['num_input_channels']=Channels of input images\n",
        "        4. net_paramsDec: dictionary defining architecture of the Encoder (see Decoder/Encoder classes)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, inputmodule_paramsEnc,net_paramsEnc,inputmodule_paramsDec,net_paramsDec):\n",
        "        super().__init__()\n",
        "\n",
        "        self.inputmodule_paramsEnc=inputmodule_paramsEnc\n",
        "        self.inputmodule_paramsDec=inputmodule_paramsDec\n",
        "        self.net_paramsEnc=net_paramsEnc\n",
        "        self.net_paramsDec=net_paramsDec\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder=Encoder(inputmodule_paramsEnc,net_paramsEnc)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder=Decoder(inputmodule_paramsDec,net_paramsDec)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "            # Guardamos el tamaño de la imagen de entrada para usarlo al final (en la fase de upsampling)\n",
        "            input_size = x.shape\n",
        "\n",
        "            # Paso por el Encoder\n",
        "            encoded = self.encoder(x)\n",
        "\n",
        "            # Paso por el Decoder\n",
        "            decoded = self.decoder(encoded)\n",
        "\n",
        "            # Upsampling a las dimensiones originales de la imagen de entrada\n",
        "            output = F.interpolate(decoded, size=input_size[2:], mode=self.upPoolMode)\n",
        "\n",
        "            return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqDAiqyGjMLm"
      },
      "source": [
        "##Annoteted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzxPNvqnjMLn",
        "outputId": "a2b3b8ea-8f4d-4363-ba6d-462bf8fb4de6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 1\n",
            "Datos (imágenes): torch.Size([16, 256, 256, 4])\n",
            "Información de ruta: {'folder': ['B22-250_0', 'B22-50_0', 'B22-241_0', 'B22-312_0', 'B22-138_0', 'B22-302_0', 'B22-155_0', 'B22-155_0', 'B22-51_0', 'B22-155_0', 'B22-240_0', 'B22-123_0', 'B22-187_0', 'B22-29_1', 'B22-249_0', 'B22-188_0'], 'image_name': ['02953.png', '00865_Aug5.png', '01489.png', '01154_Aug4.png', '00699_Aug8.png', '00168_Aug8.png', '00065_Aug6.png', '04440_Aug5.png', '00392_Aug4.png', '01518.png', '00500_Aug7.png', '00687_Aug7.png', '00591.png', '00024.png', '01018.png', '00256.png']}\n",
            "\n",
            "Datos del Excel:\n",
            "PAT_ID: B22-129, Window_ID: 659, Presence: -1\n",
            "PAT_ID: B22-68, Window_ID: 352, Presence: -1\n",
            "PAT_ID: B22-52, Window_ID: 760, Presence: -1\n",
            "PAT_ID: B22-124, Window_ID: 902_Aug8, Presence: 1\n",
            "PAT_ID: B22-46, Window_ID: 1340_Aug8, Presence: 1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Función para cargar imágenes y sus rutas desde una estructura de carpetas\n",
        "def load_images_with_paths(folder_path, excel_path, sample_size=200):\n",
        "    # Leer el archivo Excel y cargar las columnas especificadas\n",
        "    df = pd.read_excel(excel_path, usecols=[\"Pat_ID\", \"Window_ID\", \"Presence\"])\n",
        "\n",
        "    # Crear un diccionario para almacenar los datos del Excel\n",
        "    excel_data = {row['Pat_ID']: {\"Window_ID\": row['Window_ID'], \"Presence\": row['Presence']}\n",
        "                  for _, row in df.iterrows()}\n",
        "\n",
        "    images_list = []\n",
        "    paths_list = []\n",
        "\n",
        "    # Recorrer todas las subcarpetas y cargar imágenes\n",
        "    for subfolder in glob(os.path.join(folder_path, '**'), recursive=True):\n",
        "        if os.path.isdir(subfolder):\n",
        "            images = glob(os.path.join(subfolder, \"*.png\"))\n",
        "\n",
        "            if images:\n",
        "                random.shuffle(images)\n",
        "                images_sampled = random.sample(images, min(sample_size, len(images)))\n",
        "\n",
        "                for image_path in images_sampled:\n",
        "                    image = Image.open(image_path)\n",
        "                    image_np = np.array(image)\n",
        "\n",
        "                    # Guardar la imagen y su información de origen\n",
        "                    images_list.append(image_np)\n",
        "                    paths_list.append({\n",
        "                        \"folder\": os.path.basename(subfolder),  # Solo el nombre de la subcarpeta\n",
        "                        \"image_name\": os.path.basename(image_path)  # Nombre del archivo de imagen\n",
        "                    })\n",
        "\n",
        "    return images_list, paths_list, excel_data\n",
        "\n",
        "class Standard_Dataset(data.Dataset):\n",
        "    def __init__(self, X, paths, Y, transformation=None):\n",
        "        super().__init__()\n",
        "        self.X = X\n",
        "        self.paths = paths\n",
        "        self.Y = Y\n",
        "        self.transformation = transformation\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.X[idx]\n",
        "        if self.transformation:\n",
        "            image = self.transformation(image)\n",
        "\n",
        "        image_tensor = torch.from_numpy(image).float()\n",
        "        path_info = self.paths[idx]\n",
        "\n",
        "        return image_tensor, path_info\n",
        "\n",
        "# Cargar los datos\n",
        "folder_path = 'C:/Users/Josep/Documents/DATSETS/Annotated/Annotated'\n",
        "excel_path = 'C:/Users/Josep/Documents/DATSETS/HP_WSI-CoordAllAnnotatedPatches.xlsx'\n",
        "sample_size = 200\n",
        "\n",
        "images, paths, excel_data = load_images_with_paths(folder_path, excel_path, sample_size)\n",
        "\n",
        "# Crear el Dataset y DataLoader\n",
        "dataset = Standard_Dataset(images, paths, excel_data)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Probar el DataLoader\n",
        "for batch_idx, (data, path_info) in enumerate(dataloader):\n",
        "    print(f\"Batch {batch_idx + 1}\")\n",
        "    print(\"Datos (imágenes):\", data.shape)\n",
        "    print(\"Información de ruta:\", path_info)\n",
        "    if batch_idx == 0:\n",
        "        break  # Solo muestra el primer batch para verificar que funciona\n",
        "\n",
        "# Mostrar algunos datos del Excel para verificar\n",
        "print(\"\\nDatos del Excel:\")\n",
        "for pat_id, info in list(excel_data.items())[:5]:  # Muestra los primeros 5 para verificar\n",
        "    print(f\"PAT_ID: {pat_id}, Window_ID: {info['Window_ID']}, Presence: {info['Presence']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate"
      ],
      "metadata": {
        "id": "TAice8ZgjQk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torchvision.utils as vutils\n",
        "import os\n",
        "\n",
        "def calculate_psnr(img1, img2):\n",
        "    \"\"\"Calcula el PSNR entre dos imágenes de entrada.\"\"\"\n",
        "    mse = nn.functional.mse_loss(img1, img2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    return 20 * torch.log10(1.0 / torch.sqrt(mse))\n",
        "\n",
        "def evaluate_model(model, dataloader, criterion, device=\"cpu\", save_reconstructions=False, save_dir=\"reconstructions\"):\n",
        "    \"\"\"\n",
        "    Evalúa el modelo de autoencoder en el conjunto de datos proporcionado.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): El modelo a evaluar.\n",
        "        dataloader (torch.utils.data.DataLoader): DataLoader con los datos de evaluación.\n",
        "        criterion (torch.nn.Module): Función de pérdida para evaluar el rendimiento.\n",
        "        device (str): Dispositivo a utilizar ('cpu' o 'cuda').\n",
        "        save_reconstructions (bool): Si es True, guarda las imágenes originales y reconstruidas.\n",
        "        save_dir (str): Directorio donde guardar las imágenes reconstruidas.\n",
        "\n",
        "    Returns:\n",
        "        dict: Diccionario con métricas de evaluación, incluyendo pérdida promedio y PSNR.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_psnr = 0\n",
        "    num_batches = 0\n",
        "\n",
        "    if save_reconstructions and not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, _) in enumerate(dataloader):\n",
        "            data = data.to(device)\n",
        "            output = model(data)\n",
        "\n",
        "            # Calcular la pérdida de reconstrucción\n",
        "            loss = criterion(output, data)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Calcular PSNR para el batch\n",
        "            batch_psnr = calculate_psnr(data, output)\n",
        "            total_psnr += batch_psnr\n",
        "            num_batches += 1\n",
        "\n",
        "            # Guardar imágenes originales y reconstruidas para diagnóstico visual\n",
        "            if save_reconstructions and batch_idx == 0:  # Solo guardar el primer batch\n",
        "                comparison = torch.cat([data[:8], output[:8]])  # Concatenar originales y reconstruidas\n",
        "                vutils.save_image(comparison.cpu(), os.path.join(save_dir, f\"reconstruction_batch{batch_idx}.png\"), nrow=8)\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    avg_psnr = total_psnr / num_batches\n",
        "\n",
        "    return {\"average_loss\": avg_loss, \"average_psnr\": avg_psnr}\n",
        "\n",
        "# Configurar el dispositivo\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Crear el modelo y cargar al dispositivo\n",
        "autoencoder = AutoEncoderCNN(\n",
        "    inputmodule_paramsEnc={'num_input_channels': 4},\n",
        "    net_paramsEnc={'block_configs': [[32], [64], [128], [256]], 'stride': [[2], [2], [2], [2]], 'drop_rate': 0.1},\n",
        "    inputmodule_paramsDec={'num_input_channels': 256},\n",
        "    net_paramsDec={'block_configs': [[128], [64], [32], [4]], 'stride': [[2], [2], [2], [2]], 'drop_rate': 0.1}\n",
        ")\n",
        "autoencoder.to(device)\n",
        "\n",
        "# Crear un DataLoader con datos de evaluación\n",
        "eval_dataset = Standard_Dataset(images, paths, excel_data)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Definir la función de pérdida\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Evaluar el modelo\n",
        "metrics = evaluate_model(autoencoder, eval_dataloader, criterion, device=device, save_reconstructions=True, save_dir=\"reconstructions\")\n",
        "\n",
        "print(\"Resultados de la evaluación:\")\n",
        "print(metrics)\n"
      ],
      "metadata": {
        "id": "xMPn1_uMjPIs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}